{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "using a classifier coef_ method to select most influential features",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMY/dx57Drh7GZ9frbmiljk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oferweintraub/finance_sent/blob/main/using_a_classifier_coef__method_to_select_most_influential_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isfnPccu1fgA"
      },
      "source": [
        "## using a classifier coef_ method to select most influential features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNXadUNy1ZdL"
      },
      "source": [
        "# get the needed libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
        "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, classification_report, accuracy_score\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_kVb5Bu1xwD"
      },
      "source": [
        "# Create a sentences list and convert them to counters using CountVectorizer\n",
        "\n",
        "sentences = ['Arabica coffee is the best cofee on earth', 'I do not like Robusta coffee', 'if you ask me for coffee I say Arabica Arabica Arabica', 'this coffee is so bad']\n",
        "sentiment = [1, 0, 1 ,0] # 1- positive, 0 -negative\n",
        "\n",
        "vect = CountVectorizer(\n",
        "    stop_words='english',\n",
        "    ngram_range = (1,1),\n",
        "    lowercase = True,\n",
        "    max_features=100\n",
        ")\n",
        "\n",
        "X = vect.fit_transform(sentences)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfVkT7BL32Uw",
        "outputId": "2b36d0a0-2955-400e-b345-3e3e5d072321"
      },
      "source": [
        "# now , let's look at both the sparse matrix and the full matrix\n",
        "\n",
        "print(f' sparse matrix {vect.vocabulary_} \\n')\n",
        "print(f' full  matrix \\n {X.toarray()} \\n')\n",
        "print(f' the size of our vocabulary is - {len(vect.vocabulary_)} \\n')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " sparse matrix {'arabica': 0, 'coffee': 5, 'best': 3, 'cofee': 4, 'earth': 6, 'like': 7, 'robusta': 8, 'ask': 1, 'say': 9, 'bad': 2} \n",
            "\n",
            " full  matrix \n",
            " [[1 0 0 1 1 1 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 1 1 0]\n",
            " [3 1 0 0 0 1 0 0 0 1]\n",
            " [0 0 1 0 0 1 0 0 0 0]] \n",
            "\n",
            " the size of our vocabulary is - 10 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqByhcAi5HSI"
      },
      "source": [
        "from the above obe can see that sentense 3 - 'if you ask me for coffe I say Arabica Arabica Arabica' is represented as line 3 in the full matrix and specifically the word 'Arabica' which has an index 0 in the sparse matrix is shown 3 times in column 0 in the full matrix. \n",
        "\n",
        "We now look at these unigrams as features for a classifier and we'll try to resolve wich feature has the most impact of the classifier decision - in this example let's choose the LogisticRegression classifier.\n",
        "\n",
        "Finally, note that the size of our vocabulary is 10 in this case and that we will have exactly 10 coefficients in the set of parameters for the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnPf8hnI6BkQ",
        "outputId": "9fa36606-3109-46c1-fc1b-ab9f347375f0"
      },
      "source": [
        "# fit the data using Logistic Regression\n",
        "\n",
        "clf = LogisticRegression (\n",
        "    random_state=42,\n",
        "    max_iter=500\n",
        ")\n",
        "\n",
        "clf.fit(X, sentiment)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP6WScGR6qHk",
        "outputId": "41b7523e-bc97-487b-e8e0-f51c14aa72ac"
      },
      "source": [
        "# let's look at the resulting coefficients\n",
        "importance =clf.coef_.flatten()\n",
        "\n",
        "# the size of the coefficients matrix and the matrix itself....\n",
        "print(f' the number of coefficients we have is -  {importance.shape[0]} \\n')\n",
        "print(f' the full vector of coefficients and their importance is \\n -  {importance} \\n')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the number of coefficients we have is -  10 \n",
            "\n",
            " the full vector of coefficients and their importance is \n",
            " -  [ 7.63508924e-01  1.51957448e-01 -2.45864223e-01  3.07636579e-01\n",
            "  3.07636579e-01  8.24045001e-07  3.07636579e-01 -2.13728981e-01\n",
            " -2.13728981e-01  1.51957448e-01] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znSKXHGdEjXJ"
      },
      "source": [
        "from looking at the table above we can see that the argument in position 0 has the largest positive value. We also remember that the position 0 is associated with 'Arabica\" tat appear 4 times in the frequency matrix and it make senese that it has a large positive value.\n",
        "\n",
        "Let's see which word has the largest negative value? --> it is definetly the word in index 2 with value of -0.24218427 ... and in index 2 we find the word 'bad' which is indeed quite negative...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0GHazIjGTpk"
      },
      "source": [
        "How can we double check it? let's make index 2 i.e. the word 'bad' even more influencial and see is it value in the coef_ matrix increases. for ths will create another set of sentences which simply has few more 'bad' in the negative sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKD2AfJEHAZF",
        "outputId": "83a8e20e-f89b-43e2-e7ad-fa9f901a79c6"
      },
      "source": [
        "sentences_with_more_bad = ['Arabica coffee is the best cofee on earth', 'I do not like Robusta bad coffee ', 'if you ask me for coffee I say Arabica Arabica Arabica', 'this coffee is so bad, bad, bad']\n",
        "\n",
        "# transfrom it to the same feature space\n",
        "X_bad = vect.transform(sentences_with_more_bad)\n",
        "\n",
        "# and look at X_bad , especially at index 2 where 'bad' is represented\n",
        "print (f' words frequency matrix after adding few bads \\n {X_bad.toarray()}')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " words frequency matrix after adding few bads \n",
            " [[1 0 0 1 1 1 1 0 0 0]\n",
            " [0 0 1 0 0 1 0 1 1 0]\n",
            " [3 1 0 0 0 1 0 0 0 1]\n",
            " [0 0 3 0 0 1 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvSlmOucIg4S",
        "outputId": "31fffeb1-cabb-4de0-e5eb-ce9f3ee75892"
      },
      "source": [
        "# let's fit again the classifier with this data\n",
        "clf.fit(X_bad, sentiment)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPwia2_ZIvVK",
        "outputId": "ca124a85-26fc-4b0a-8361-d5bf390a455d"
      },
      "source": [
        "# and let's look now at the coeffcients...we expect position 2 to be large and negative\n",
        "importance =clf.coef_.flatten()\n",
        "\n",
        "print(f' the number of coefficients we have is -  {importance.shape[0]} \\n')\n",
        "print(f' the full vector of coefficients and their importance is \\n   {importance} \\n')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the number of coefficients we have is -  10 \n",
            "\n",
            " the full vector of coefficients and their importance is \n",
            "   [ 6.06899893e-01  1.24463714e-01 -6.08389854e-01  2.33508750e-01\n",
            "  2.33508750e-01  2.04423891e-06  2.33508750e-01 -2.32760703e-01\n",
            " -2.32760703e-01  1.24463714e-01] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtS15EfCJYGJ"
      },
      "source": [
        "indeed the 2nd term is now large and negative as expected. We only need now to correlate those features with words... which we do below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFL_JeyAJzgD",
        "outputId": "2480bd1b-2520-4f95-9a3a-ac56ddfbf33f"
      },
      "source": [
        "# find the most influencial terms for positive and negative sentiment\n",
        "\n",
        "TOP_N = 10\n",
        "\n",
        "# gey key (word) for a given index\n",
        "def get_feature(features_dict, val):\n",
        "    for key, value in features_dict.items():\n",
        "         if val == value:\n",
        "             return key\n",
        " \n",
        "    return \"key doesn't exist\"\n",
        "\n",
        "# reverse a list\n",
        "def reverse(lst):\n",
        "    new_lst = lst[::-1]\n",
        "    return new_lst\n",
        "\n",
        "counter = 0\n",
        "features_pos = {}\n",
        "features_neg = {}\n",
        "\n",
        "for param in reverse(list(np.argsort(abs(importance)))):\n",
        "  counter +=1\n",
        "  if counter >= TOP_N:\n",
        "    break\n",
        "  else:\n",
        "   if importance[param] >= 0: # print only the positives\n",
        "    key = get_feature(vect.vocabulary_, param)\n",
        "    value = importance[param]\n",
        "    features_pos[key] = value\n",
        "   else:\n",
        "    key = get_feature(vect.vocabulary_, param)\n",
        "    value = importance[param]\n",
        "    features_neg[key] = value \n",
        "\n",
        "print(f' top terms contributing to positives:\\n {features_pos} \\n')\n",
        "print(f' top terms contributing to negatives: \\n {features_neg} \\n')\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " top terms contributing to positives:\n",
            " {'arabica': 0.6068998925439615, 'earth': 0.2335087499111397, 'cofee': 0.2335087499111397, 'best': 0.2335087499111397, 'say': 0.12446371421094059, 'ask': 0.12446371421094059} \n",
            "\n",
            " top terms contributing to negatives: \n",
            " {'bad': -0.6083898539890195, 'robusta': -0.23276070283024977, 'like': -0.23276070283024977} \n",
            "\n"
          ]
        }
      ]
    }
  ]
}